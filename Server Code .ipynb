{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def create_clients(Features_list, Targets_list, num_clients=10, initial='clients'):\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "       \n",
    "    #shard data and place at each client\n",
    "    size = len(df)//num_clients\n",
    "    shards = [df[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    #number of clients must equal number of shards\n",
    "    assert(len(shards) == len(client_names))\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))}\n",
    "def batch_data(data_shard, bs=32):\n",
    "    #seperate shard into two lists\n",
    "    data = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data)))\n",
    "    return dataset.shuffle(len(Features_list)).batch(bs)\n",
    "\n",
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, activation= \"relu\",input_shape=(9,)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(64, activation= \"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation= \"relu\"))\n",
    "        return model\n",
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client    local_count=tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "    return avg_grad\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    mse = tf.keras.losses.MeanAbsoluteError()\n",
    "    y_pred = model.predict(X_test)\n",
    "    loss = mse(y_test,y_pred)\n",
    "    print('global_loss:',loss.numpy())\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
